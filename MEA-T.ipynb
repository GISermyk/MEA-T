{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd289e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minyu\\AppData\\Local\\Temp\\ipykernel_12696\\2132832138.py:1: FutureWarning: icepyx v1.x is being deprecated; the back-end systems on which it relies\n",
      "will be shut down as of late 2024. At that time, upgrade to icepyx v2.x, which uses the\n",
      "new NASA Harmony back-end, will be required. Please see\n",
      "<https://icepyx.readthedocs.io/en/latest/user_guide/changelog/v1.3.0.html> for more\n",
      "information!\n",
      "\n",
      "  import icepyx as ipx\n",
      "c:\\Users\\minyu\\.conda\\envs\\ICESAT_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.7.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.2/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.2.min.js\", \"https://cdn.holoviz.org/panel/1.6.2/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='90d68351-b024-4d4b-8bd5-a70d7353688a'>\n",
       "  <div id=\"b1bb72e3-364e-460d-9821-0ba834bb5528\" data-root-id=\"90d68351-b024-4d4b-8bd5-a70d7353688a\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"b7d13dc1-9df5-48a6-8e64-775f89cba1ec\":{\"version\":\"3.7.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"90d68351-b024-4d4b-8bd5-a70d7353688a\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"3bf10548-4874-4356-afd3-a18471ef0886\",\"attributes\":{\"plot_id\":\"90d68351-b024-4d4b-8bd5-a70d7353688a\",\"comm_id\":\"345c6cecfabf4c5b81e2178c0e2533e7\",\"client_comm_id\":\"141a8dffdd744168bbd7101e4e42098c\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"b7d13dc1-9df5-48a6-8e64-775f89cba1ec\",\"roots\":{\"90d68351-b024-4d4b-8bd5-a70d7353688a\":\"b1bb72e3-364e-460d-9821-0ba834bb5528\"},\"root_ids\":[\"90d68351-b024-4d4b-8bd5-a70d7353688a\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "90d68351-b024-4d4b-8bd5-a70d7353688a"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import icepyx as ipx\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os, json\n",
    "from pprint import pprint\n",
    "import dask.dataframe as dd\n",
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "from readers.get_ATL03_x_atc import get_atl03_x_atc\n",
    "from readers.read_HDF5_ATL03 import read_hdf5_atl03_beam, read_hdf5_atl03_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3323997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "\n",
    "from readers.add_atl08_info import add_atl08_classed_flag\n",
    "from readers.get_ATL03_x_atc import get_atl03_x_atc\n",
    "from readers.read_HDF5_ATL03 import read_hdf5_atl03_beam_h5py\n",
    "\n",
    "def read_hdf5_atl03_beam_h5py(filename, beam, verbose=False):\n",
    "    \"\"\"\n",
    "    ATL03 原始数据读取\n",
    "    Args:\n",
    "        filename (str): h5文件路径\n",
    "        beam (str): 光束\n",
    "        verbose (bool): 输出HDF5信息\n",
    "\n",
    "    Returns:\n",
    "        返回ATL03光子数据的heights和geolocation信息\n",
    "    \"\"\"\n",
    "\n",
    "    # 打开HDF5文件进行读取\n",
    "    file_id = h5py.File(os.path.expanduser(filename), 'r')\n",
    "\n",
    "    # 输出HDF5文件信息\n",
    "    if verbose:\n",
    "        print(file_id.filename)\n",
    "        print(list(file_id.keys()))\n",
    "        print(list(file_id['METADATA'].keys()))\n",
    "\n",
    "    # 为ICESat-2 ATL03变量和属性分配python字典\n",
    "    atl03_mds = {}\n",
    "\n",
    "    # 读取文件中每个输入光束\n",
    "    beams = [k for k in file_id.keys() if bool(re.match('gt\\\\d[lr]', k))]\n",
    "    if beam not in beams:\n",
    "        print('请填入正确的光束代码')\n",
    "        return\n",
    "\n",
    "    atl03_mds['heights'] = {}\n",
    "    atl03_mds['geolocation'] = {}\n",
    "    atl03_mds['bckgrd_atlas'] = {}\n",
    "\n",
    "    # -- 获取每个HDF5变量\n",
    "    # -- ICESat-2 Measurement Group\n",
    "    for key, val in file_id[beam]['heights'].items():\n",
    "        atl03_mds['heights'][key] = val[:]\n",
    "\n",
    "    # -- ICESat-2 Geolocation Group\n",
    "    for key, val in file_id[beam]['geolocation'].items():\n",
    "        atl03_mds['geolocation'][key] = val[:]\n",
    "\n",
    "    for key, val in file_id[beam]['bckgrd_atlas'].items():\n",
    "        atl03_mds['bckgrd_atlas'][key] = val[:]\n",
    "\n",
    "    return atl03_mds\n",
    "\n",
    "def get_atl03_x_atc(atl03_mds):\n",
    "    val = atl03_mds\n",
    "\n",
    "    # 初始化\n",
    "    val['heights']['x_atc'] = np.zeros_like(val['heights']['h_ph']) + np.nan\n",
    "    val['heights']['y_atc'] = np.zeros_like(val['heights']['h_ph']) + np.nan\n",
    "    val['geolocation']['ref_elev_all'] = np.zeros_like(val['heights']['h_ph'])\n",
    "\n",
    "    # -- ATL03 Segment ID\n",
    "    segment_id = val['geolocation']['segment_id']\n",
    "    # -- 分段中的第一个光子（转换为基于0的索引）\n",
    "    segment_index_begin = val['geolocation']['ph_index_beg'] - 1\n",
    "    # -- 分段中的光子事件数\n",
    "    segment_pe_count = val['geolocation']['segment_ph_cnt']\n",
    "    # -- 每个ATL03段的沿轨道距离\n",
    "    segment_distance = val['geolocation']['segment_dist_x']\n",
    "    # -- 每个ATL03段的轨道长度\n",
    "    segment_length = val['geolocation']['segment_length']\n",
    "\n",
    "    # -- 对ATL03段进行迭代，以计算40m的平均值\n",
    "    # -- 在ATL03中基于1的索引：无效==0\n",
    "    # -- 此处为基于0的索引：无效==-1\n",
    "    segment_indices, = np.nonzero((segment_index_begin[:-1] >= 0) &\n",
    "                                  (segment_index_begin[1:] >= 0))\n",
    "    for j in segment_indices:\n",
    "        # -- j 段索引\n",
    "        idx = segment_index_begin[j]\n",
    "        # -- 分段中的光子数（使用2个ATL03分段）\n",
    "        c1 = np.copy(segment_pe_count[j])\n",
    "        c2 = np.copy(segment_pe_count[j + 1])\n",
    "        cnt = c1 + c2\n",
    "\n",
    "        # -- 沿轨道和跨轨道距离\n",
    "        # -- 获取当前段光子列表，idx当前段(j)第一个光子数量，c1当前段光子数量，idx+c1当前段长度\n",
    "        distance_along_x = np.copy(val['heights']['dist_ph_along'][idx: idx + cnt])\n",
    "        ref_elev = np.copy(val['geolocation']['ref_elev'][j])\n",
    "        # -- 给当前段的光子加上当前段沿轨道距离\n",
    "        distance_along_x[:c1] += segment_distance[j]\n",
    "        distance_along_x[c1:] += segment_distance[j + 1]\n",
    "        distance_along_y = np.copy(val['heights']['dist_ph_across'][idx: idx + cnt])\n",
    "\n",
    "        val['heights']['x_atc'][idx: idx + cnt] = distance_along_x\n",
    "        val['heights']['y_atc'][idx: idx + cnt] = distance_along_y\n",
    "        val['geolocation']['ref_elev_all'][idx: idx + c1] += ref_elev\n",
    "\n",
    "def read_data(filepath, beam, mask_lat, mask_lon):\n",
    "    \"\"\"\n",
    "    读取数据，返回沿轨道距离和高程距离\n",
    "    :param filepath: h5文件路径\n",
    "    :param beam: 轨道光束\n",
    "    :param mask_lat: 维度范围\n",
    "    :param mask_lon: 经度范围\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    atl03_file = glob(filepath)\n",
    "    is2_atl03_mds = read_hdf5_atl03_beam(atl03_file[0], beam=beam, verbose=False)\n",
    "    # 添加沿轨道距离到数据中\n",
    "    get_atl03_x_atc(is2_atl03_mds)\n",
    "    # 选择范围\n",
    "    d3 = is2_atl03_mds\n",
    "    subset1 = (d3['heights']['lat_ph'] >= min(mask_lat)) & (d3['heights']['lat_ph'] <= max(mask_lat))\n",
    "    print(subset1.shape, 'sss')\n",
    "    zz = d3['heights']['h_ph']\n",
    "    print(zz.shape, 'zz')\n",
    "    if mask_lon is not None:\n",
    "        if mask_lon[0] is not None and mask_lon[1] is None:\n",
    "            subset1 = subset1 & (d3['heights']['x_atc'] >= mask_lon[0])\n",
    "        elif mask_lon[0] is None and mask_lon[1] is not None:\n",
    "            subset1 = subset1 & (d3['heights']['x_atc'] <= mask_lon[1])\n",
    "        else:\n",
    "            subset1 = subset1 & (d3['heights']['x_atc'] >= min(mask_lon)) & (d3['heights']['x_atc'] <= max(mask_lon))\n",
    "    x_act = d3['heights']['x_atc'][subset1]\n",
    "    h = d3['heights']['h_ph'][subset1]\n",
    "    \n",
    "    signal_conf_ph = d3['heights']['signal_conf_ph'][subset1]\n",
    "    lat = d3['heights']['lat_ph'][subset1]\n",
    "    lon = d3['heights']['lon_ph'][subset1]\n",
    "    ref_elev = d3['geolocation']['ref_elev_all'][subset1]\n",
    "    print(d3['heights'])\n",
    "    print(d3.keys())\n",
    "    print(d3['heights'].keys(), 'height')\n",
    "    print(d3['geolocation'].keys(), 'location key')\n",
    "    print(d3['bckgrd_atlas'].keys(), 'bckgrd_atlas')\n",
    "    print(d3['heights']['quality_ph'], 'quality_ph')\n",
    "    del d3, subset1\n",
    "    return x_act, h, signal_conf_ph, lat, lon, ref_elev\n",
    "\n",
    "def read_all_beam_coordinate(filepath, mask_lat, mask_lon):\n",
    "    \"\"\"\n",
    "    读取所有波束的数据\n",
    "    :param filepath:\n",
    "    :param mask_lat:\n",
    "    :param mask_lon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    atl03_file = glob(filepath)\n",
    "    is2_atl03_mds = read_hdf5_atl03_coordinate(atl03_file[0])\n",
    "\n",
    "    # 禁止加载全部数据\n",
    "    # if mask_lat is None or len(mask_lat) == 0 or mask_lon is None or len(mask_lon) == 0:\n",
    "    #     return False\n",
    "\n",
    "    d3 = is2_atl03_mds\n",
    "    if mask_lon is None and mask_lat is None:\n",
    "        # 加载全部数据\n",
    "        return d3\n",
    "    for beam in is2_atl03_mds.keys():\n",
    "        subset1 = (d3[beam]['lat'] >= min(mask_lat)) & (d3[beam]['lat'] <= max(mask_lat))\n",
    "        subset1 = subset1 & (d3[beam]['lon'] >= min(mask_lon)) & (d3[beam]['lon'] <= max(mask_lon))\n",
    "        d3[beam]['lat'] = d3[beam]['lat'][subset1]\n",
    "        d3[beam]['lon'] = d3[beam]['lon'][subset1]\n",
    "    return d3\n",
    "\n",
    "def read_hdf5_atl08(filename, beam, verbose=False):\n",
    "    file_id = h5py.File(os.path.expanduser(filename), 'r')\n",
    "\n",
    "    # 输出HDF5文件信息\n",
    "    if verbose:\n",
    "        print(file_id.filename)\n",
    "        print(list(file_id.keys()))\n",
    "        print(list(file_id['METADATA'].keys()))\n",
    "    # 为ICESat-2 ATL08变量和属性分配python字典\n",
    "    atl08_mds = {}\n",
    "\n",
    "    # 读取文件中每个输入光束\n",
    "    beams = [k for k in file_id.keys() if bool(re.match('gt\\\\d[lr]', k))]\n",
    "    if beam not in beams:\n",
    "        print('请填入正确的光束代码')\n",
    "        return\n",
    "    # atl08_land_segement = {}\n",
    "    # for key, val in file_id[beam]['land_segments'].items():\n",
    "    #     atl08_land_segement['land_segments'][key] = val[:]\n",
    "    atl08_mds['land_segments'] = {}\n",
    "    atl08_mds['signal_photons'] = {}\n",
    "    print(atl08_mds)\n",
    "    # -- ICESat-2 Geolocation Group\n",
    "    for key, val in file_id[beam]['signal_photons'].items():\n",
    "        print(val)\n",
    "        atl08_mds['signal_photons'][key] = val[:]\n",
    "\n",
    "    return atl08_mds\n",
    "\n",
    "def select_atl03_data(atl03_data, mask, TF_height_range):\n",
    "    \"\"\"\n",
    "    选择数据范围\n",
    "    Args:\n",
    "        atl03_data: 所有数据\n",
    "        mask (list): 维度范围\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # 选择范围\n",
    "    d3 = atl03_data\n",
    "    subset1 = (d3['heights']['lon_ph'] > min(mask[0])) & (d3['heights']['lon_ph'] < max(mask[0])) & (d3['heights']['lat_ph'] > min(mask[1])) & (d3['heights']['lat_ph'] < max(mask[1])) & (d3['classed_pc_flag'] == 1) & (d3['heights']['h_ph'] > TF_height_range[0]) & (d3['heights']['h_ph'] < TF_height_range[1]) \n",
    "\n",
    "    x_act = d3['heights']['x_atc'][subset1]\n",
    "    h = d3['heights']['h_ph'][subset1]\n",
    "    signal_conf_ph = d3['heights']['signal_conf_ph'][subset1]\n",
    "    lat = d3['heights']['lat_ph'][subset1]\n",
    "    lon = d3['heights']['lon_ph'][subset1]\n",
    "    classed_pc_flag = d3['classed_pc_flag'][subset1]\n",
    "\n",
    "    return x_act, h, signal_conf_ph, lat, lon, classed_pc_flag\n",
    "\n",
    "def get_atl03_data(filepath, beam):\n",
    "    \"\"\"\n",
    "    读取ATL03数据，根据维度截取数据\n",
    "    Args:\n",
    "        filepath (str): h5文件路径\n",
    "        beam (str): 光束\n",
    "    Returns:\n",
    "        返回沿轨道距离，高程距离，光子置信度\n",
    "    \"\"\"\n",
    "    atl03_file = glob.glob(filepath)\n",
    "    is2_atl03_mds = read_hdf5_atl03_beam_h5py(atl03_file[0], beam=beam, verbose=False)\n",
    "    # 添加沿轨道距离到数据中\n",
    "    get_atl03_x_atc(is2_atl03_mds)\n",
    "    return is2_atl03_mds\n",
    "from readers.get_ATL03_x_atc import get_atl03_x_atc\n",
    "from readers.read_HDF5_ATL03 import read_hdf5_atl03_beam, read_hdf5_atl03_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d96f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def get_atl_group(folder_path_03, folder_path_08):\n",
    "\n",
    "    alt03_file_list = glob.glob(os.path.join(folder_path_03, '*ATL03*.h5'))\n",
    "    n = len(alt03_file_list)\n",
    "\n",
    "    ATL_name_group = []\n",
    "    for i in range(n):\n",
    "        \n",
    "        # find keyword (date and orbit number)\n",
    "        file_path = alt03_file_list[i]\n",
    "        time_match = re.search(r'ATL03_(\\d{14})_', file_path)\n",
    "        orbit_match = re.search(r'ATL03_\\d{14}_(\\d{8})_', file_path)\n",
    "        Imaging_date = time_match.group(1)[:8]\n",
    "        orbit_num = orbit_match.group(1)\n",
    "\n",
    "        # search target ATL03/08 file with the same keyword (data)\n",
    "        alt03_file_list_ = glob.glob(os.path.join(folder_path_03, f'*ATL03*{Imaging_date}*{orbit_num}*.h5'))\n",
    "        alt08_file_list = glob.glob(os.path.join(folder_path_08, f'*ATL08*{Imaging_date}*{orbit_num}*.h5'))\n",
    "        \n",
    "        # Construct ATL_pair and storage in ATL_name_group( 2-D List)\n",
    "        if (len(alt08_file_list) == 1) & (len(alt08_file_list) == 1):\n",
    "            ATL_pair = [alt03_file_list_[0], alt08_file_list[0]]\n",
    "            ATL_name_group.append(ATL_pair)\n",
    "\n",
    "    return ATL_name_group\n",
    "\n",
    "def find_anomaly(indices_list):\n",
    "    b = []\n",
    "    if len(indices_list) <= 5:\n",
    "        value = 100\n",
    "    else:\n",
    "        for i in range(1,len(indices_list)):\n",
    "            b.append(indices_list[i] - indices_list[i-1])\n",
    "            \n",
    "        if max(b) > 5:\n",
    "            index_max = [index for index, value in enumerate(b) if value == max(b)]\n",
    "            value = indices_list[index_max[0]+1]\n",
    "        else:\n",
    "            value = indices_list[0]\n",
    "        \n",
    "    return value\n",
    "\n",
    "def sea_height_cal(input, height_name, derivative_thred):\n",
    "    \n",
    "    if  isinstance(input, str):\n",
    "        data = pd.read_csv(input)\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        df = input\n",
    "    \n",
    "    percentile, derivative, derivative_2th = [], [0], [0]\n",
    "    height_TS = pd.DataFrame()\n",
    "    \n",
    "    if len(df) < 100:\n",
    "        return 0, height_TS\n",
    "    else:\n",
    "        \n",
    "        for i in range(0, 101):\n",
    "            p = np.percentile(df[height_name], i)\n",
    "            percentile.append(p)\n",
    "\n",
    "        height_TS['percentile'] = percentile\n",
    "        \n",
    "        height_TS['percentile'][:5] = height_TS['percentile'][5]\n",
    "        \n",
    "        short_window, long_window = 5, 10\n",
    "        height_TS['EMA5'] = height_TS['percentile'].ewm(span=short_window, adjust=False).mean()\n",
    "        height_TS['EMA10'] = height_TS['percentile'].ewm(span=long_window, adjust=False).mean()\n",
    "        height_TS['MACD'] = height_TS['EMA5'] - height_TS['EMA10']\n",
    "\n",
    "        indices = [index for index, value in enumerate(height_TS['MACD']) if value > derivative_thred]\n",
    "        target_index = find_anomaly(indices)\n",
    "        # if indices == []:\n",
    "        #     indices = [100]\n",
    "\n",
    "        print(indices[:10], 'indices')\n",
    "        print(target_index, 'target_index')\n",
    "        # sea_height = percentile[target_index]\n",
    "        sea_height = percentile[target_index]\n",
    "        \n",
    "        return  sea_height, df#, height_TS, target_index\n",
    "    \n",
    "def sea_height_cal_for_view(input, height_name, derivative_thred):\n",
    "    \n",
    "    if  isinstance(input, str):\n",
    "        data = pd.read_csv(input)\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        df = input\n",
    "    \n",
    "    percentile, derivative, derivative_2th = [], [0], [0]\n",
    "    height_TS = pd.DataFrame()\n",
    "    \n",
    "    if len(df) < 100:\n",
    "        return 0, height_TS\n",
    "    else:\n",
    "        \n",
    "        for i in range(0, 101):\n",
    "            p = np.percentile(df[height_name], i)\n",
    "            percentile.append(p)\n",
    "\n",
    "        height_TS['percentile'] = percentile\n",
    "        short_window, long_window = 5, 10\n",
    "        # height_TS['EMA5'] = height_TS['percentile'].ewm(span=short_window, adjust=False).mean()\n",
    "        # height_TS['EMA10'] = height_TS['percentile'].ewm(span=long_window, adjust=False).mean()\n",
    "        # height_TS['MACD'] = height_TS['EMA5'] - height_TS['EMA10']\n",
    "        \n",
    "        height_TS['percentile'][:5] = height_TS['percentile'][5]\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "        height_TS['EMA5'] = height_TS['percentile'].ewm(span=short_window, adjust=False).mean()\n",
    "        height_TS['EMA10'] = height_TS['percentile'].ewm(span=long_window, adjust=False).mean()\n",
    "        height_TS['MACD'] = height_TS['EMA5'] - height_TS['EMA10']\n",
    "        # height_TS['MACD'] = height_TS['Z'].ewm(span=5, adjust=False).mean()\n",
    "        # height_TS['DEA'] =  height_TS['DIF'].ewm(span=25, adjust=False).mean()\n",
    "        # height_TS['MACD'] = height_TS['DIF'] - height_TS['DEA']\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "        indices = [index for index, value in enumerate(height_TS['MACD']) if value > derivative_thred]\n",
    "        target_index = find_anomaly(indices)\n",
    "        # if indices == []:\n",
    "        #     indices = [100]\n",
    "\n",
    "        print(indices[:10], 'indices')\n",
    "        print(target_index, 'target_index')\n",
    "        #sea_height = percentile[target_index]\n",
    "        sea_height = percentile[target_index]\n",
    "        return  sea_height, df , height_TS, target_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4fea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icesat_gt_processing(alt03_path, alt08_path, beam, region_mask, TF_height_range, gap_distance, sea_thred, is_display = True):\n",
    "    \n",
    "    sea_height_list = []\n",
    "    df_list = []\n",
    "    df_sea_point_remove_list = []\n",
    "    \n",
    "    # calculate each beams\n",
    "    for i in range(len(beam)):\n",
    "    \n",
    "        atl03_data = get_atl03_data(alt03_path, beam[i])\n",
    "        add_atl08_classed_flag(alt08_path, beam[i], atl03_data)\n",
    "        x_origin, y_origin, conf, lat, lon, classed_pc_flag = select_atl03_data(atl03_data, region_mask, TF_height_range)\n",
    "        z = pd.DataFrame()\n",
    "        z['X_Along_track'], z['height'], z['latitude'], z['longtitude'] = x_origin, y_origin, lat, lon\n",
    "        z['distance'] = (z['X_Along_track'] // gap_distance) * gap_distance\n",
    "        re_accumulate =  z.groupby('distance').agg(\n",
    "            \n",
    "            mean_height = ('height', 'mean'),\n",
    "            mean_lon = ('longtitude', 'mean'),\n",
    "            mean_lat = ('latitude', 'mean')\n",
    "        ).reset_index()\n",
    "\n",
    "        if re_accumulate.empty | len(re_accumulate) < 200:\n",
    "            continue\n",
    "\n",
    "        sea_height, df, height_TS, target_index = sea_height_cal_for_view(re_accumulate, 'mean_height', sea_thred)  \n",
    "        if sea_height > 0:\n",
    "            sea_height_list.append(sea_height)\n",
    "            df_list.append(df)    \n",
    "    \n",
    "    if sea_height_list == []:\n",
    "        empty = pd.DataFrame()\n",
    "        return empty, [], [], []\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------  \n",
    "    log = []\n",
    "    log.append('sea height list:' + str(sea_height_list) + ' --- ')\n",
    "\n",
    "    # calculate Final_sea_height\n",
    "    \n",
    "    print(sea_height_list, 'sea_height_list')\n",
    "    if np.max(sea_height_list) - np.min(sea_height_list) > 1:\n",
    "        sort_ = np.sort(sea_height_list)\n",
    "        print('sorted', sort_, type(sort_))\n",
    "        _ = []\n",
    "        for i in range(len(sea_height_list)-1):\n",
    "            _.append(sort_[i+1] - sort_[i])\n",
    "\n",
    "        index_max = [index for index, value in enumerate(_ ) if value == max(_)]\n",
    "\n",
    "        if (index_max[0]+1) <= len(sort_)/2:\n",
    "            index_max = len(sort_)-1\n",
    "        \n",
    "        Final_sea_height = sort_[index_max].item()\n",
    "    else:\n",
    "        Final_sea_height = np.max(sea_height_list)\n",
    "\n",
    "    print(Final_sea_height,'Final_sea_height', type(Final_sea_height))\n",
    "    log.append('Final_sea_height :'+ str(Final_sea_height) + '\\n')\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Apply Final_sea_height for all beams\n",
    "    for j in range(len(df_list)):\n",
    "        mask = df_list[j]['mean_height'] > Final_sea_height\n",
    "        print(type(mask), 'type mask', len(mask), 'mask len')\n",
    "        \n",
    "        df_sea_point_remove = df_list[j][mask]\n",
    "        \n",
    "        if df_sea_point_remove.empty:\n",
    "            print(filepath_03 + '_' + beam[j] + ' is empty')\n",
    "        \n",
    "        df_sea_point_remove_list.append(df_sea_point_remove)\n",
    "        \n",
    "        df_list[j]['sea_height'] = Final_sea_height\n",
    "        df_list[j]['sea_point'] =  df_list[j]['mean_height'] <= Final_sea_height\n",
    "        \n",
    "        if is_display:\n",
    "           \n",
    "            plt.figure(figsize=(10, 3))\n",
    "            plt.plot(df_list[j]['mean_height'], color ='gray',label = 'height')\n",
    "            plt.plot(df_list[j]['sea_height'], color = 'blue' , linestyle = '--', label = 'sea_height')\n",
    "            plt.scatter(df_list[j].index[df_list[j]['sea_point']], df_list[j]['mean_height'][df_list[j]['sea_point']], color = 'red', label = 'sea points', zorder = 0.5)\n",
    "            plt.legend()\n",
    "            plt.ylabel('height')\n",
    "            plt.xlabel('photons')\n",
    "            plt.show()\n",
    "            \n",
    "            fig, ax1 = plt.subplots(figsize=(10,3))\n",
    "            _ = np.arange(0, 101)\n",
    "            ax1.plot(_, height_TS['percentile'], label = 'percentile', color = 'black')\n",
    "            ax1.set_xlabel('X-axis')\n",
    "            ax1.set_ylabel('Height(m)', color = 'black')\n",
    "            ax1.tick_params(axis='y', labelcolor='black')\n",
    "           # ax1.axhline(df_list[j]['sea_height'][0], color = 'red', linestyle = '--')\n",
    "            ax1.legend()\n",
    "            \n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(_, height_TS['MACD'], 'r--', label = 'MACD', color = 'blue')\n",
    "           # ax2.plot(_, height_TS['Signal'], 'r--', label = 'Signal', color = 'green')\n",
    "            ax2.set_ylabel('MACD', color = 'blue')\n",
    "\n",
    "            ax2.tick_params(axis = 'y', labelcolor = 'blue')\n",
    "            ax2.axhline(0, color = 'gray', linestyle = '--')\n",
    "            ax2.axvline(target_index, color = 'red', linestyle = '--', label = 'Threshold')\n",
    "            ax2.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "            #-------------------------------------\n",
    "    \n",
    "    merged_df = pd.concat(df_sea_point_remove_list, ignore_index=True)\n",
    "    \n",
    "    return merged_df, sea_height_list, Final_sea_height, log\n",
    "\n",
    "def icesat_gt_processing2(No ,alt03_path, alt08_path, beam, region_mask, gap_distance, sea_thred, is_display = False):\n",
    "    \n",
    "\n",
    "    sea_height_list = []\n",
    "    df_list = []\n",
    "    df_sea_point_remove_list = []\n",
    "    \n",
    "    # calculate each beams\n",
    "    for i in range(len(beam)):\n",
    "    \n",
    "        atl03_data = get_atl03_data(alt03_path, beam[i])\n",
    "        add_atl08_classed_flag(alt08_path, beam[i], atl03_data)\n",
    "        x_origin, y_origin, conf, lat, lon, classed_pc_flag = select_atl03_data(atl03_data, region_mask)\n",
    "        z = pd.DataFrame()\n",
    "        z['X_Along_track'], z['height'], z['latitude'], z['longtitude'] = x_origin, y_origin, lat, lon\n",
    "        z['distance'] = (z['X_Along_track'] // gap_distance) * gap_distance\n",
    "        re_accumulate =  z.groupby('distance').agg(\n",
    "            \n",
    "            mean_height = ('height', 'mean'),\n",
    "            mean_lon = ('longtitude', 'mean'),\n",
    "            mean_lat = ('latitude', 'mean')\n",
    "        ).reset_index()\n",
    "\n",
    "        if re_accumulate.empty | len(re_accumulate) < 200 :\n",
    "            continue\n",
    "\n",
    "        sea_height, df = sea_height_cal(re_accumulate, 'mean_height', sea_thred)  \n",
    "        df['Strip_No'] =  str(No) + '_' + beam[i]\n",
    "        \n",
    "        if sea_height > 0:\n",
    "            sea_height_list.append(sea_height)\n",
    "            df_list.append(df)    \n",
    "    \n",
    "    if sea_height_list == []:\n",
    "        empty = pd.DataFrame()\n",
    "        return empty, [], [], []\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------  \n",
    "    log = []\n",
    "    log.append('sea height list:' + str(sea_height_list) + ' --- ')\n",
    "\n",
    "    # calculate Final_sea_height\n",
    "    \n",
    "    print(sea_height_list, 'sea_height_list')\n",
    "    if np.max(sea_height_list) - np.min(sea_height_list) > 1:\n",
    "        sort_ = np.sort(sea_height_list)\n",
    "        print('sorted', sort_, type(sort_))\n",
    "        _ = []\n",
    "        for i in range(len(sea_height_list)-1):\n",
    "            _.append(sort_[i+1] - sort_[i])\n",
    "\n",
    "        index_max = [index for index, value in enumerate(_ ) if value == max(_)]\n",
    "\n",
    "        if (index_max[0]+1) <= len(sort_)/2:\n",
    "            index_max = len(sort_)-1\n",
    "        \n",
    "        Final_sea_height = sort_[index_max].item()\n",
    "    else:\n",
    "        Final_sea_height = np.max(sea_height_list)\n",
    "\n",
    "    print(Final_sea_height,'Final_sea_height', type(Final_sea_height))\n",
    "    log.append('Final_sea_height :'+ str(Final_sea_height) + '\\n')\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Apply Final_sea_height for all beams\n",
    "    for j in range(len(df_list)):\n",
    "        mask = df_list[j]['mean_height'] > Final_sea_height\n",
    "        print(type(mask), 'type mask', len(mask), 'mask len')\n",
    "        \n",
    "        df_sea_point_remove = df_list[j][mask]\n",
    "        \n",
    "        if df_sea_point_remove.empty:\n",
    "            print(filepath_03 + '_' + beam[j] + ' is empty')\n",
    "        \n",
    "        df_sea_point_remove_list.append(df_sea_point_remove)\n",
    "        \n",
    "        df_list[j]['sea_height'] = Final_sea_height\n",
    "        df_list[j]['sea_point'] =  df_list[j]['mean_height'] <= Final_sea_height\n",
    "        \n",
    "        if is_display:\n",
    "        \n",
    "            plt.figure(figsize=(10, 3))\n",
    "            plt.plot(df_list[j]['mean_height'], color ='gray',label = 'height')\n",
    "            plt.plot(df_list[j]['sea_height'], color = 'blue' , linestyle = '--', label = 'sea_height')\n",
    "            plt.scatter(df_list[j].index[df_list[j]['sea_point']], df_list[j]['mean_height'][df_list[j]['sea_point']], color = 'red', label = 'sea points', zorder = 0.5)\n",
    "            plt.legend()\n",
    "            plt.ylabel('height')\n",
    "            plt.xlabel('photons')\n",
    "            plt.show()\n",
    "            #############\n",
    "    \n",
    "    merged_df = pd.concat(df_sea_point_remove_list, ignore_index=True)\n",
    "    \n",
    "    return merged_df, sea_height_list, Final_sea_height, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "878df2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "def icesat_gt_processing3(No ,alt03_path, alt08_path, beam, region_mask, TF_height_range, gap_distance, sea_thred, is_display = False):\n",
    "    \n",
    "    Land_use_classification = 'E:\\Downloads/tes/LULC_thames.tif'\n",
    "    osgm_path = 'G:\\OSGM15\\Great_Britain_osgm15.tif'\n",
    "    df_sea_point_remove_list = []\n",
    "    local_strip_height_list = []\n",
    "    log = []\n",
    "    \n",
    "    for i in range(len(beam)):\n",
    "        \n",
    "        df_list = []\n",
    "        sea_height_list = []\n",
    "        \n",
    "        for j in range(len(beam[i])):\n",
    "            \n",
    "            atl03_data = get_atl03_data(alt03_path, beam[i][j])\n",
    "            add_atl08_classed_flag(alt08_path, beam[i][j], atl03_data)\n",
    "            x_origin, y_origin, conf, lat, lon, classed_pc_flag = select_atl03_data(atl03_data, region_mask, TF_height_range)\n",
    "            z = pd.DataFrame()\n",
    "            z['X_Along_track'], z['height'], z['latitude'], z['longtitude'] = x_origin, y_origin, lat, lon\n",
    "            z['distance'] = (z['X_Along_track'] // gap_distance) * gap_distance\n",
    "            re_accumulate =  z.groupby('distance').agg(\n",
    "                \n",
    "                mean_height = ('height', 'mean'),\n",
    "                mean_lon = ('longtitude', 'mean'),\n",
    "                mean_lat = ('latitude', 'mean')\n",
    "            ).reset_index()\n",
    "\n",
    "            if Land_use_classification is not None and not re_accumulate.empty:\n",
    "                #coords = [(lon, lat) for lon, lat in zip(re_accumulate['mean_lon'], re_accumulate['mean_lat'])]\n",
    "                \n",
    "                \n",
    "                raster = rasterio.open(Land_use_classification)\n",
    "                transformer = Transformer.from_crs(4326, raster.crs, always_xy=True)\n",
    "                xs, ys = transformer.transform(re_accumulate['mean_lon'].values, re_accumulate['mean_lat'].values)\n",
    "                coords = list(zip(xs, ys))\n",
    "                re_accumulate['LU_class'] = [val[0] if val is not None else None for val in raster.sample(coords)]\n",
    "                \n",
    "                # remove land \n",
    "                mask = (re_accumulate['LU_class'] == 200) | (re_accumulate['LU_class'] == 80) | (re_accumulate['LU_class'] == 90)\n",
    "                re_accumulate = re_accumulate[mask]\n",
    "            \n",
    "\n",
    "\n",
    "            if re_accumulate.empty | len(re_accumulate) < 200:\n",
    "                continue\n",
    "\n",
    "            sea_height, df = sea_height_cal(re_accumulate, 'mean_height', sea_thred)  \n",
    "            df['Strip_No'] =  str(No) + '_' + beam[i][j]\n",
    "        \n",
    "            if sea_height > 0:\n",
    "                sea_height_list.append(sea_height)\n",
    "                df_list.append(df)  \n",
    "             \n",
    "        if sea_height_list == []:\n",
    "            # empty = pd.DataFrame()\n",
    "            # return empty, [], [], []\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------------------------------------------  \n",
    "        \n",
    "        log.append('sea height list:' + str(sea_height_list) + ' --- ')\n",
    "\n",
    "        # calculate Final_sea_height\n",
    "        \n",
    "        Final_sea_height = np.max(sea_height_list)\n",
    "        local_strip_height_list.append(Final_sea_height)\n",
    "        \n",
    "        log.append('Final_sea_height :'+ str(Final_sea_height) + '\\n')\n",
    "        \n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Apply Final_sea_height for all beams\n",
    "        for k in range(len(df_list)):\n",
    "            mask = df_list[k]['mean_height'] > Final_sea_height\n",
    "            print(type(mask), 'type mask', len(mask), 'mask len')\n",
    "            \n",
    "            df_sea_point_remove = df_list[k][mask]\n",
    "            \n",
    "            if df_sea_point_remove.empty:\n",
    "                print(filepath_03 + '_' + beam[i][0] + beam[i][1] + ' is empty')\n",
    "            \n",
    "            df_sea_point_remove_list.append(df_sea_point_remove)\n",
    "            \n",
    "            df_list[k]['sea_height'] = Final_sea_height\n",
    "            df_list[k]['sea_point'] =  df_list[k]['mean_height'] <= Final_sea_height\n",
    "            \n",
    "            if is_display:\n",
    "            \n",
    "                plt.figure(figsize=(10, 3))\n",
    "                plt.plot(df_list[k]['mean_height'], color ='gray',label = 'height')\n",
    "                plt.plot(df_list[k]['sea_height'], color = 'blue' , linestyle = '--', label = 'sea_height')\n",
    "                plt.scatter(df_list[k].index[df_list[k]['sea_point']], df_list[k]['mean_height'][df_list[k]['sea_point']], color = 'red', label = 'sea points', zorder = 0.5)\n",
    "                plt.legend()\n",
    "                plt.ylabel('height')\n",
    "                plt.xlabel('photons')\n",
    "                plt.show()\n",
    "                #############\n",
    "        \n",
    "        merged_df = pd.concat(df_sea_point_remove_list, ignore_index=True)\n",
    "        \n",
    "    if len(local_strip_height_list) == 0:\n",
    "        empty = pd.DataFrame()\n",
    "        return empty, [], [], []\n",
    "        \n",
    "    # else:\n",
    "    #     if np.max(local_strip_height_list) - np.min(local_strip_height_list) > 0.5:\n",
    "        \n",
    "    #         mask = merged_df['mean_height'] > np.max(local_strip_height_list)\n",
    "    #         merged_df = merged_df[mask]\n",
    "        \n",
    "    return merged_df, sea_height_list, Final_sea_height, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972c52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "def icesat_gt_processing3_new(No ,alt03_path, alt08_path, beam, region_mask, TF_height_range, gap_distance, sea_thred, is_display = False):\n",
    "    \n",
    "    \n",
    "    osgm_path = 'G:\\OSGM15\\Great_Britain_osgm15.tif'\n",
    "    df_sea_point_remove_list = []\n",
    "    local_strip_height_list = []\n",
    "    log = []\n",
    "    \n",
    "    for i in range(len(beam)):\n",
    "        \n",
    "        df_list = []\n",
    "        sea_height_list = []\n",
    "        \n",
    "        for j in range(len(beam[i])):\n",
    "            \n",
    "            atl03_data = get_atl03_data(alt03_path, beam[i][j])\n",
    "            add_atl08_classed_flag(alt08_path, beam[i][j], atl03_data)\n",
    "            x_origin, y_origin, conf, lat, lon, classed_pc_flag = select_atl03_data(atl03_data, region_mask, TF_height_range)\n",
    "            z = pd.DataFrame()\n",
    "            z['X_Along_track'], z['height'], z['latitude'], z['longtitude'] = x_origin, y_origin, lat, lon\n",
    "            z['distance'] = (z['X_Along_track'] // gap_distance) * gap_distance\n",
    "            re_accumulate =  z.groupby('distance').agg(\n",
    "                \n",
    "                mean_height = ('height', 'mean'),\n",
    "                mean_lon = ('longtitude', 'mean'),\n",
    "                mean_lat = ('latitude', 'mean')\n",
    "            ).reset_index()\n",
    "\n",
    "\n",
    "            if osgm_path is not None and not re_accumulate.empty:\n",
    "                \n",
    "                \n",
    "                raster = rasterio.open(osgm_path)\n",
    "                transformer = Transformer.from_crs(4326, raster.crs, always_xy=True)\n",
    "                xs, ys = transformer.transform(re_accumulate['mean_lon'].values, re_accumulate['mean_lat'].values)\n",
    "                coords = list(zip(xs, ys))\n",
    "                re_accumulate['OSGM'] = [val[0] if val is not None else None for val in raster.sample(coords)]\n",
    "                \n",
    "                # raster = rasterio.open(osgm_path)\n",
    "                # coords = [(lon, lat) for lon, lat in zip(re_accumulate['mean_lon'], re_accumulate['mean_lat'])]\n",
    "                # re_accumulate['OSGM'] = [val[0] if val is not None else None for val in raster.sample(coords)]\n",
    "                re_accumulate['OH'] = re_accumulate['mean_height'] - re_accumulate['OSGM']\n",
    "                \n",
    "                # remove land \n",
    "                mask = (re_accumulate['OH'] < 10) & (re_accumulate['OH'] > -10) \n",
    "                re_accumulate = re_accumulate[mask]\n",
    "            \n",
    "\n",
    "\n",
    "            if re_accumulate.empty | len(re_accumulate) < 200:\n",
    "                print('photon less than 200!')\n",
    "                continue\n",
    "\n",
    "            sea_height, df = sea_height_cal(re_accumulate, 'mean_height', sea_thred)  \n",
    "            df['Strip_No'] =  str(No) + '_' + beam[i][j]\n",
    "        \n",
    "            if sea_height > 0:\n",
    "                sea_height_list.append(sea_height)\n",
    "                df_list.append(df)  \n",
    "             \n",
    "        if sea_height_list == []:\n",
    "            # empty = pd.DataFrame()\n",
    "            # return empty, [], [], []\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------------------------------------------  \n",
    "        \n",
    "        log.append('sea height list:' + str(sea_height_list) + ' --- ')\n",
    "\n",
    "        # calculate Final_sea_height\n",
    "        \n",
    "        Final_sea_height = np.max(sea_height_list)\n",
    "        local_strip_height_list.append(Final_sea_height)\n",
    "        \n",
    "        log.append('Final_sea_height :'+ str(Final_sea_height) + '\\n')\n",
    "        \n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Apply Final_sea_height for all beams\n",
    "        for k in range(len(df_list)):\n",
    "            mask = df_list[k]['mean_height'] > Final_sea_height\n",
    "            print(type(mask), 'type mask', len(mask), 'mask len')\n",
    "            \n",
    "            df_sea_point_remove = df_list[k][mask]\n",
    "            \n",
    "            if df_sea_point_remove.empty:\n",
    "                print(filepath_03 + '_' + beam[i][0] + beam[i][1] + ' is empty')\n",
    "            \n",
    "            df_sea_point_remove_list.append(df_sea_point_remove)\n",
    "            \n",
    "            df_list[k]['sea_height'] = Final_sea_height\n",
    "            df_list[k]['sea_point'] =  df_list[k]['mean_height'] <= Final_sea_height\n",
    "            \n",
    "            if is_display:\n",
    "            \n",
    "                plt.figure(figsize=(10, 3))\n",
    "                plt.plot(df_list[k]['mean_height'], color ='gray',label = 'height')\n",
    "                plt.plot(df_list[k]['sea_height'], color = 'blue' , linestyle = '--', label = 'sea_height')\n",
    "                plt.scatter(df_list[k].index[df_list[k]['sea_point']], df_list[k]['mean_height'][df_list[k]['sea_point']], color = 'red', label = 'sea points', zorder = 0.5)\n",
    "                plt.legend()\n",
    "                plt.ylabel('height')\n",
    "                plt.xlabel('photons')\n",
    "                plt.show()\n",
    "                #############\n",
    "        \n",
    "        merged_df = pd.concat(df_sea_point_remove_list, ignore_index=True)\n",
    "        \n",
    "    if len(local_strip_height_list) == 0:\n",
    "        empty = pd.DataFrame()\n",
    "        return empty, [], [], []\n",
    "        \n",
    "    # else:\n",
    "    #     if np.max(local_strip_height_list) - np.min(local_strip_height_list) > 0.5:\n",
    "        \n",
    "    #         mask = merged_df['mean_height'] > np.max(local_strip_height_list)\n",
    "    #         merged_df = merged_df[mask]\n",
    "        \n",
    "    return merged_df, sea_height_list, Final_sea_height, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ddd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "\n",
    "def icesat_gt_processing4(alt03_path, alt08_path, beam, region_mask, TF_height_range, gap_distance, sea_thred, is_display = True):\n",
    "    \n",
    "    sea_height_list = []\n",
    "    df_list = []\n",
    "    df_sea_point_remove_list = []\n",
    "    \n",
    "    \n",
    "    Land_use_classification = 'E:\\Downloads/tes/LULC_thames.tif'\n",
    "    # if Land_use_classification is not None:\n",
    "    #     raster = rasterio.open(Land_use_classification)\n",
    "    # calculate each beams\n",
    "    for i in range(len(beam)):\n",
    "    \n",
    "        atl03_data = get_atl03_data(alt03_path, beam[i])\n",
    "        add_atl08_classed_flag(alt08_path, beam[i], atl03_data)\n",
    "        x_origin, y_origin, conf, lat, lon, classed_pc_flag = select_atl03_data(atl03_data, region_mask, TF_height_range)\n",
    "        z = pd.DataFrame()\n",
    "        z['X_Along_track'], z['height'], z['latitude'], z['longtitude'] = x_origin, y_origin, lat, lon\n",
    "        z['distance'] = (z['X_Along_track'] // gap_distance) * gap_distance\n",
    "        re_accumulate =  z.groupby('distance').agg(\n",
    "            \n",
    "            mean_height = ('height', 'mean'),\n",
    "            mean_lon = ('longtitude', 'mean'),\n",
    "            mean_lat = ('latitude', 'mean')\n",
    "        ).reset_index()\n",
    "        \n",
    "    \n",
    "        if Land_use_classification is not None and not re_accumulate.empty:\n",
    "            #coords = [(lon, lat) for lon, lat in zip(re_accumulate['mean_lon'], re_accumulate['mean_lat'])]\n",
    "            \n",
    "            \n",
    "            raster = rasterio.open(Land_use_classification)\n",
    "            transformer = Transformer.from_crs(4326, raster.crs, always_xy=True)\n",
    "            xs, ys = transformer.transform(re_accumulate['mean_lon'].values, re_accumulate['mean_lat'].values)\n",
    "            coords = list(zip(xs, ys))\n",
    "            re_accumulate['LU_class'] = [val[0] if val is not None else None for val in raster.sample(coords)]\n",
    "            \n",
    "            # remove land \n",
    "            mask = (re_accumulate['LU_class'] == 200) | (re_accumulate['LU_class'] == 80) | (re_accumulate['LU_class'] == 90)\n",
    "            re_accumulate = re_accumulate[mask]\n",
    "            \n",
    "        if re_accumulate.empty | len(re_accumulate) < 50:\n",
    "            continue\n",
    "\n",
    "        sea_height, df, height_TS, target_index = sea_height_cal_for_view(re_accumulate, 'mean_height', sea_thred)  \n",
    "        if sea_height > 0:\n",
    "            sea_height_list.append(sea_height)\n",
    "            df_list.append(df)    \n",
    "    \n",
    "    if sea_height_list == []:\n",
    "        empty = pd.DataFrame()\n",
    "        return empty, [], [], []\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------  \n",
    "    log = []\n",
    "    log.append('sea height list:' + str(sea_height_list) + ' --- ')\n",
    "\n",
    "    # calculate Final_sea_height\n",
    "    \n",
    "    print(sea_height_list, 'sea_height_list')\n",
    "    if np.max(sea_height_list) - np.min(sea_height_list) > 1:\n",
    "        sort_ = np.sort(sea_height_list)\n",
    "        print('sorted', sort_, type(sort_))\n",
    "        _ = []\n",
    "        for i in range(len(sea_height_list)-1):\n",
    "            _.append(sort_[i+1] - sort_[i])\n",
    "\n",
    "        index_max = [index for index, value in enumerate(_ ) if value == max(_)]\n",
    "\n",
    "        if (index_max[0]+1) <= len(sort_)/2:\n",
    "            index_max = len(sort_)-1\n",
    "        \n",
    "        Final_sea_height = sort_[index_max].item()\n",
    "    else:\n",
    "        Final_sea_height = np.max(sea_height_list)\n",
    "\n",
    "    print(Final_sea_height,'Final_sea_height', type(Final_sea_height))\n",
    "    log.append('Final_sea_height :'+ str(Final_sea_height) + '\\n')\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Apply Final_sea_height for all beams\n",
    "    for j in range(len(df_list)):\n",
    "        mask = df_list[j]['mean_height'] > Final_sea_height\n",
    "        print(type(mask), 'type mask', len(mask), 'mask len')\n",
    "        \n",
    "        df_sea_point_remove = df_list[j][mask]\n",
    "        \n",
    "        if df_sea_point_remove.empty:\n",
    "            print(filepath_03 + '_' + beam[j] + ' is empty')\n",
    "        \n",
    "        df_sea_point_remove_list.append(df_sea_point_remove)\n",
    "        \n",
    "        df_list[j]['sea_height'] = Final_sea_height\n",
    "        df_list[j]['sea_point'] =  df_list[j]['mean_height'] <= Final_sea_height\n",
    "        \n",
    "        if is_display:\n",
    "           \n",
    "            plt.figure(figsize=(10, 3))\n",
    "            plt.plot(df_list[j]['mean_height'], color ='gray',label = 'height')\n",
    "            plt.plot(df_list[j]['sea_height'], color = 'blue' , linestyle = '--', label = 'sea_height')\n",
    "            plt.scatter(df_list[j].index[df_list[j]['sea_point']], df_list[j]['mean_height'][df_list[j]['sea_point']], color = 'red', label = 'sea points', zorder = 0.5)\n",
    "            plt.legend()\n",
    "            plt.ylabel('height')\n",
    "            plt.xlabel('photons')\n",
    "            plt.show()\n",
    "            \n",
    "            fig, ax1 = plt.subplots(figsize=(10,3))\n",
    "            _ = np.arange(0, 101)\n",
    "            ax1.plot(_, height_TS['percentile'], label = 'percentile', color = 'black')\n",
    "            ax1.set_xlabel('X-axis')\n",
    "            ax1.set_ylabel('Height(m)', color = 'black')\n",
    "            ax1.tick_params(axis='y', labelcolor='black')\n",
    "           # ax1.axhline(df_list[j]['sea_height'][0], color = 'red', linestyle = '--')\n",
    "            ax1.legend()\n",
    "            \n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(_, height_TS['MACD'], 'r--', label = 'MACD', color = 'blue')\n",
    "           # ax2.plot(_, height_TS['Signal'], 'r--', label = 'Signal', color = 'green')\n",
    "            ax2.set_ylabel('MACD', color = 'blue')\n",
    "\n",
    "            ax2.tick_params(axis = 'y', labelcolor = 'blue')\n",
    "            ax2.axhline(0, color = 'gray', linestyle = '--')\n",
    "            ax2.axvline(target_index, color = 'red', linestyle = '--', label = 'Threshold')\n",
    "            ax2.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "            #-------------------------------------\n",
    "    \n",
    "    merged_df = pd.concat(df_sea_point_remove_list, ignore_index=True)\n",
    "    \n",
    "    return merged_df, sea_height_list, Final_sea_height, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_03  = 'G:\\ICESat-2\\Region2\\Region2_2019\\ATL03_Region2_2019'\n",
    "folder_path_08 = 'G:\\ICESat-2\\Region2\\Region2_2019\\ATL08_Region2_2019' \n",
    "# mask = [[0.273, 1.475], [51.262, 51.863]]\n",
    "mask = [[-0.839, 0.382], [53.164, 53.852]]\n",
    "\n",
    "# mask = Region_info[detect_region]['mask']\n",
    "\n",
    "# folder_path_03  = f'H:\\Region4\\Region4_{year}\\ATL03_Region4_{year}'\n",
    "# folder_path_08 =  f'H:\\Region4\\Region4_{year}\\ATL08_Region4_{year}' \n",
    "beam = ['gt1l', 'gt2l', 'gt3l', 'gt1r', 'gt2r', 'gt3r']\n",
    "beam = [['gt1l', 'gt1r'],['gt2l', 'gt2r'],['gt3l', 'gt3r']]\n",
    "beam3 = [['gt1l', 'gt1r']]\n",
    "beam = ['gt3r']\n",
    "TF_height_range = [30, 70]\n",
    "\n",
    "No = 31\n",
    "ATL_name_group = get_atl_group(folder_path_03, folder_path_08)\n",
    "filepath_03 = ATL_name_group[No][0]\n",
    "filepath_08 = ATL_name_group[No][1]\n",
    "print(filepath_08)\n",
    "\n",
    "# merged_df3, _, _, log = icesat_gt_processing(filepath_03, filepath_08, beam, mask, TF_height_range, 30, sea_thred = 0.05, is_display = True)\n",
    "\n",
    "merged_df3, _, _, log = icesat_gt_processing3_new(9, filepath_03, filepath_08, beam3, mask, TF_height_range, 30, sea_thred = 0.1, is_display = True)\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "# import pandas as pd\n",
    "# output_path = f'G:\\ICESat-2\\Region2_map\\Henber_map\\A2019/test\\z{No}_{beam[0]}_new.shp'\n",
    "# geometry = [Point(xy) for xy in zip(merged_df3['mean_lon'], merged_df3['mean_lat'])]\n",
    "# gdf = gpd.GeoDataFrame(merged_df3, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "# gdf.to_file(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "output_path = f'G:\\ICESat-2\\Region1_map\\Thames_map\\A2020/test\\z{No}_{beam[0]}.shp'\n",
    "geometry = [Point(xy) for xy in zip(merged_df['mean_lon'], merged_df['mean_lat'])]\n",
    "gdf = gpd.GeoDataFrame(merged_df, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "gdf.to_file(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c61ba",
   "metadata": {},
         "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 359 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220127181424_05571406_006_01.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 387 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220127181424_05571406_006_01.h5_gt1lgt1r is empty\n",
      "[] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1466 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220127181424_05571406_006_01.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 1498 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220127181424_05571406_006_01.h5_gt2lgt2r is empty\n",
      "[81, 82, 83, 84, 85, 86, 87, 88, 89, 90] indices\n",
      "81 target_index\n",
      "[81, 82, 83, 84, 85, 86, 87, 88, 89, 90] indices\n",
      "81 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1835 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1818 mask len\n",
      "------------------------------------\n",
      "No_3_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220127181424_05571406_006_01.h5 is done\n",
      "5.88% is done\n",
      "[91, 92, 93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "91 target_index\n",
      "[18, 19, 20, 21, 22, 23, 98, 99, 100] indices\n",
      "98 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 300 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 293 mask len\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20] indices\n",
      "86 target_index\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23] indices\n",
      "93 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 302 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 288 mask len\n",
      "[12, 13, 14, 15, 16, 17, 18, 19, 20, 21] indices\n",
      "92 target_index\n",
      "[70, 71, 72, 73, 74, 75, 76, 77, 78, 97] indices\n",
      "97 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 282 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 280 mask len\n",
      "------------------------------------\n",
      "No_4_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220131180605_06181406_006_01.h5 is done\n",
      "7.84% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[86, 87, 88, 89, 90, 91, 92, 93, 94, 95] indices\n",
      "86 target_index\n",
      "[90, 91, 92, 93, 94, 95, 96, 97, 98, 99] indices\n",
      "90 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 270 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 269 mask len\n",
      "------------------------------------\n",
      "No_5_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220215045936_08391402_006_01.h5 is done\n",
      "9.8% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[99, 100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 651 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220312034401_12201402_006_01.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 566 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220312034401_12201402_006_01.h5_gt1lgt1r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 400 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220312034401_12201402_006_01.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 361 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220312034401_12201402_006_01.h5_gt2lgt2r is empty\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[79, 80, 81, 82, 83, 84, 85, 86, 87, 88] indices\n",
      "79 target_index\n",
      "[94, 95, 96, 97, 98, 99, 100] indices\n",
      "94 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 299 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 247 mask len\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "------------------------------------\n",
      "No_8_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220316033541_12811402_006_01.h5 is done\n",
      "15.69% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[65, 66, 67, 68, 69, 70, 71, 72, 73, 74] indices\n",
      "65 target_index\n",
      "[68, 69, 70, 71, 72, 73, 74, 75, 76, 77] indices\n",
      "68 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 292 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 285 mask len\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "------------------------------------\n",
      "No_11_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220403150953_01761506_006_02.h5 is done\n",
      "21.57% is done\n",
      "[73, 74, 75, 76, 77, 78, 79, 80, 81, 82] indices\n",
      "73 target_index\n",
      "[71, 72, 73, 74, 75, 76, 77, 78, 79, 80] indices\n",
      "71 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 460 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 470 mask len\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73] indices\n",
      "64 target_index\n",
      "[67, 68, 69, 70, 71, 72, 73, 74, 75, 76] indices\n",
      "67 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 503 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 486 mask len\n",
      "[78, 79, 80, 81, 82, 83, 84, 85, 86, 87] indices\n",
      "78 target_index\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89] indices\n",
      "80 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 582 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 572 mask len\n",
      "------------------------------------\n",
      "No_12_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220414021113_03361502_006_02.h5 is done\n",
      "23.53% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[73, 74, 75, 76, 77, 78, 79, 80, 81, 82] indices\n",
      "73 target_index\n",
      "[73, 74, 75, 76, 77, 78, 79, 80, 81, 82] indices\n",
      "73 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1557 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1567 mask len\n",
      "[] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 2017 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220610232350_12201502_006_01.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 2029 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220610232350_12201502_006_01.h5_gt2lgt2r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 2049 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220610232350_12201502_006_01.h5_gt3lgt3r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 2054 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220610232350_12201502_006_01.h5_gt3lgt3r is empty\n",
      "------------------------------------\n",
      "No_20_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220610232350_12201502_006_01.h5 is done\n",
      "39.22% is done\n",
      "[53, 54, 55, 56, 57, 58, 59, 60, 61, 62] indices\n",
      "53 target_index\n",
      "[53, 54, 55, 56, 57, 58, 59, 60, 61, 62] indices\n",
      "53 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 297 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 301 mask len\n",
      "[69, 70, 71, 72, 73, 74, 75, 76, 77, 78] indices\n",
      "69 target_index\n",
      "[69, 70, 71, 72, 73, 74, 75, 76, 77, 78] indices\n",
      "69 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 276 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 280 mask len\n",
      "[91, 92, 93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "91 target_index\n",
      "[86, 87, 88, 89, 90, 91, 92, 93, 94, 95] indices\n",
      "86 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 211 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 221 mask len\n",
      "------------------------------------\n",
      "No_21_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220614231534_12811502_006_01.h5 is done\n",
      "41.18% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[56, 57, 58, 59, 60, 61, 62, 63, 64, 65] indices\n",
      "56 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 242 mask len\n",
      "photon less than 200!\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20] indices\n",
      "79 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 216 mask len\n",
      "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18] indices\n",
      "34 target_index\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20] indices\n",
      "11 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 547 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 706 mask len\n",
      "------------------------------------\n",
      "No_23_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220629105812_01151606_006_01.h5 is done\n",
      "45.1% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16] indices\n",
      "83 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 205 mask len\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "------------------------------------\n",
      "No_24_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220703104951_01761606_006_02.h5 is done\n",
      "47.06% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18] indices\n",
      "9 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 632 mask len\n",
      "------------------------------------\n",
      "No_26_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220728093414_05571606_006_02.h5 is done\n",
      "50.98% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18] indices\n",
      "65 target_index\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20] indices\n",
      "65 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1709 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1728 mask len\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] indices\n",
      "88 target_index\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20] indices\n",
      "87 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1871 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1880 mask len\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20] indices\n",
      "83 target_index\n",
      "[8, 9, 10, 11, 12, 13, 14, 15, 16, 17] indices\n",
      "82 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1770 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1770 mask len\n",
      "------------------------------------\n",
      "No_28_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220811202749_07781602_006_01.h5 is done\n",
      "54.9% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 497 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220909190351_12201602_006_01.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 544 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220909190351_12201602_006_01.h5_gt1lgt1r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 621 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220909190351_12201602_006_01.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 665 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220909190351_12201602_006_01.h5_gt2lgt2r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 256 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220909190351_12201602_006_01.h5_gt3lgt3r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 296 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220909190351_12201602_006_01.h5_gt3lgt3r is empty\n",
      "[93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "93 target_index\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96, 97] indices\n",
      "88 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 274 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 286 mask len\n",
      "[93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "93 target_index\n",
      "[92, 93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "92 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 272 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 280 mask len\n",
      "[19, 20, 21, 22, 23, 24, 25, 26, 97, 98] indices\n",
      "97 target_index\n",
      "[13, 14, 15, 16, 17, 18, 19, 20, 97, 98] indices\n",
      "97 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 279 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 281 mask len\n",
      "------------------------------------\n",
      "No_34_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220913185531_12811602_006_01.h5 is done\n",
      "66.67% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24] indices\n",
      "15 target_index\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24] indices\n",
      "73 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 917 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 944 mask len\n",
      "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18] indices\n",
      "9 target_index\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] indices\n",
      "66 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 817 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 927 mask len\n",
      "[12, 13, 14, 15, 16, 17, 18, 19, 20, 21] indices\n",
      "52 target_index\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] indices\n",
      "52 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 550 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 590 mask len\n",
      "------------------------------------\n",
      "No_37_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20220928063802_01151706_006_01.h5 is done\n",
      "72.55% is done\n",
      "[67, 68, 69, 70, 71, 72, 73, 74, 75, 76] indices\n",
      "67 target_index\n",
      "[69, 70, 71, 72, 73, 74, 75, 76, 77, 78] indices\n",
      "69 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 230 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 266 mask len\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "------------------------------------\n",
      "No_38_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221002062941_01761706_006_01.h5 is done\n",
      "74.51% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[100] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 359 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221027051400_05571706_006_01.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 390 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221027051400_05571706_006_01.h5_gt1lgt1r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1111 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221027051400_05571706_006_01.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 1342 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221027051400_05571706_006_01.h5_gt2lgt2r is empty\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96, 97] indices\n",
      "88 target_index\n",
      "[79, 80, 81, 82, 83, 84, 85, 86, 87, 88] indices\n",
      "79 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1344 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1505 mask len\n",
      "------------------------------------\n",
      "No_41_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221027051400_05571706_006_01.h5 is done\n",
      "80.39% is done\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 294 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 292 mask len\n",
      "[75, 76, 77, 78, 79, 80, 81, 82, 83, 84] indices\n",
      "75 target_index\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 290 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 294 mask len\n",
      "[66, 67, 68, 69, 70, 71, 72, 73, 74, 75] indices\n",
      "66 target_index\n",
      "[66, 67, 68, 69, 70, 71, 72, 73, 74, 75] indices\n",
      "66 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 296 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 298 mask len\n",
      "------------------------------------\n",
      "No_42_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221031050541_06181706_006_01.h5 is done\n",
      "82.35% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[100] indices\n",
      "100 target_index\n",
      "[99, 100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 679 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221209144328_12201702_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 652 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20221209144328_12201702_006_02.h5_gt1lgt1r is empty\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[89, 90, 91, 92, 93, 94, 95, 96, 97, 98] indices\n",
      "89 target_index\n",
      "[91, 92, 93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "91 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 296 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 293 mask len\n",
      "[82, 83, 84, 85, 86, 87, 88, 89, 90, 91] indices\n",
      "82 target_index\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 264 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 280 mask len\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "------------------------------------\n",
      "No_50_G:\\ICESat-2\\Region1\\Region1_2022\\ATL03_Region1_2022\\ATL03_20230101020924_01761806_006_02.h5 is done\n",
      "98.04% is done\n",
      "output_len:  11157\n",
      "     distance  mean_height  mean_lon   mean_lat       OSGM        OH Strip_No\n",
      "0  14171520.0    48.490688  0.856625  52.969169  44.833000  3.657688   0_gt1l\n",
      "1  14171550.0    49.494133  0.856576  52.968885  44.833000  4.661133   0_gt1l\n",
      "2  14171580.0    49.217834  0.856528  52.968610  44.833000  4.384834   0_gt1l\n",
      "3  14171610.0    48.072533  0.856478  52.968316  44.845001  3.227531   0_gt1l\n",
      "4  14171670.0    47.755405  0.856401  52.967846  44.845001  2.910404   0_gt1l\n",
      "5  14171700.0    47.850353  0.856354  52.967541  44.845001  3.005352   0_gt1l\n",
      "6  14171730.0    48.001881  0.856312  52.967266  44.845001  3.156879   0_gt1l\n",
      "7  14171760.0    48.145962  0.856283  52.967078  44.845001  3.300961   0_gt1l\n",
      "8  14172900.0    49.458000  0.854623  52.956855  44.859001  4.598999   0_gt1l\n",
      "9  14172930.0    51.131496  0.854573  52.956554  44.859001  6.272495   0_gt1l\n",
      "[89, 90, 91, 92, 93, 94, 95, 96, 97, 98] indices\n",
      "89 target_index\n",
      "[91, 92, 93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "91 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 296 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 293 mask len\n",
      "[82, 83, 84, 85, 86, 87, 88, 89, 90, 91] indices\n",
      "82 target_index\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 264 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 280 mask len\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "------------------------------------\n",
      "No_0_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230101020924_01761806_006_02.h5 is done\n",
      "0.0% is done\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92, 93] indices\n",
      "84 target_index\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89] indices\n",
      "80 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 347 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 365 mask len\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "[86, 87, 88, 89, 90, 91, 92, 93, 94, 95] indices\n",
      "86 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 359 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 361 mask len\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "[13, 86, 87, 88, 89, 90, 91, 92, 93, 94] indices\n",
      "86 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 369 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 370 mask len\n",
      "------------------------------------\n",
      "No_1_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230111131112_03361802_006_02.h5 is done\n",
      "1.92% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 359 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230126005359_05571806_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 386 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230126005359_05571806_006_02.h5_gt1lgt1r is empty\n",
      "[] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1467 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230126005359_05571806_006_02.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 1495 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230126005359_05571806_006_02.h5_gt2lgt2r is empty\n",
      "[81, 82, 83, 84, 85, 86, 87, 88, 89, 90] indices\n",
      "81 target_index\n",
      "[82, 83, 84, 85, 86, 87, 88, 89, 90, 91] indices\n",
      "82 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1836 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1817 mask len\n",
      "------------------------------------\n",
      "No_3_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230126005359_05571806_006_02.h5 is done\n",
      "5.77% is done\n",
      "[98, 99, 100] indices\n",
      "100 target_index\n",
      "[98, 99, 100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 337 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230130004530_06181806_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 338 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230130004530_06181806_006_02.h5_gt1lgt1r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 274 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230130004530_06181806_006_02.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 281 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230130004530_06181806_006_02.h5_gt2lgt2r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 206 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230130004530_06181806_006_02.h5_gt3lgt3r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 207 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230130004530_06181806_006_02.h5_gt3lgt3r is empty\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[92, 93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "92 target_index\n",
      "[75, 76, 77, 78, 79, 80, 81, 82, 83, 84] indices\n",
      "75 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 587 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 771 mask len\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16] indices\n",
      "84 target_index\n",
      "[8, 9, 10, 11, 12, 13, 14, 15, 16, 17] indices\n",
      "68 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 808 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1079 mask len\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16] indices\n",
      "73 target_index\n",
      "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18] indices\n",
      "68 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1302 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1579 mask len\n",
      "------------------------------------\n",
      "No_6_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230209114720_07781802_006_02.h5 is done\n",
      "11.54% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69] indices\n",
      "60 target_index\n",
      "[11, 12, 13, 14, 15, 61, 62, 63, 64, 65] indices\n",
      "61 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1323 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1287 mask len\n",
      "[79, 80, 81, 82, 83, 84, 85, 86, 87, 88] indices\n",
      "79 target_index\n",
      "[78, 79, 80, 81, 82, 83, 84, 85, 86, 87] indices\n",
      "78 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 740 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 732 mask len\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96, 97] indices\n",
      "88 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 638 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 601 mask len\n",
      "------------------------------------\n",
      "No_9_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230227232130_10601806_006_02.h5 is done\n",
      "17.31% is done\n",
      "[99, 100] indices\n",
      "100 target_index\n",
      "[98, 99, 100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 262 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230314101457_12811802_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 255 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230314101457_12811802_006_02.h5_gt1lgt1r is empty\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96, 97] indices\n",
      "88 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 291 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 286 mask len\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96, 97] indices\n",
      "88 target_index\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96, 97] indices\n",
      "88 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 300 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 278 mask len\n",
      "------------------------------------\n",
      "No_10_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230314101457_12811802_006_02.h5 is done\n",
      "19.23% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 432 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 422 mask len\n",
      "[70, 71, 72, 73, 74, 75, 76, 77, 78, 79] indices\n",
      "70 target_index\n",
      "[8, 9, 10, 11, 12, 13, 14, 15, 70, 71] indices\n",
      "70 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 447 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 402 mask len\n",
      "[68, 69, 70, 71, 72, 73, 74, 75, 76, 77] indices\n",
      "68 target_index\n",
      "[71, 72, 73, 74, 75, 76, 77, 78, 79, 80] indices\n",
      "71 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 537 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 512 mask len\n",
      "------------------------------------\n",
      "No_13_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230412085055_03361902_006_02.h5 is done\n",
      "25.0% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 430 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230426203330_05571906_006_02.h5_gt3lgt3r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 439 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230426203330_05571906_006_02.h5_gt3lgt3r is empty\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25] indices\n",
      "55 target_index\n",
      "photon less than 200!\n",
      "<class 'pandas.core.series.Series'> type mask 292 mask len\n",
      "------------------------------------\n",
      "No_17_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230511072700_07781902_006_02.h5 is done\n",
      "32.69% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[100] indices\n",
      "100 target_index\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16] indices\n",
      "97 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 739 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230609060244_12201902_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 279 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230609060244_12201902_006_02.h5_gt1lgt1r is empty\n",
      "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18] indices\n",
      "98 target_index\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16] indices\n",
      "94 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 545 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 217 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230609060244_12201902_006_02.h5_gt2lgt2r is empty\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "------------------------------------\n",
      "No_21_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230609060244_12201902_006_02.h5 is done\n",
      "40.38% is done\n",
      "[71, 72, 73, 74, 75, 76, 77, 78, 79, 80] indices\n",
      "71 target_index\n",
      "[69, 70, 71, 72, 73, 74, 75, 76, 77, 78] indices\n",
      "69 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 287 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 296 mask len\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69] indices\n",
      "60 target_index\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73] indices\n",
      "64 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 290 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 264 mask len\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 308 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 309 mask len\n",
      "------------------------------------\n",
      "No_22_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230613055425_12811902_006_02.h5 is done\n",
      "42.31% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "[73, 74, 75, 76, 77, 78, 79, 80, 81, 82] indices\n",
      "73 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 452 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 461 mask len\n",
      "[70, 71, 72, 73, 74, 75, 76, 77, 78, 79] indices\n",
      "70 target_index\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 544 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 520 mask len\n",
      "[83, 84, 85, 86, 87, 88, 89, 90, 91, 92] indices\n",
      "83 target_index\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96] indices\n",
      "87 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 580 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 569 mask len\n",
      "------------------------------------\n",
      "No_26_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230712043018_03362002_006_02.h5 is done\n",
      "50.0% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[8, 9, 10, 11, 12, 13, 14, 15, 16, 17] indices\n",
      "98 target_index\n",
      "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 595 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230726161243_05572006_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 204 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230726161243_05572006_006_02.h5_gt1lgt1r is empty\n",
      "[61, 62, 63, 64, 65, 66, 67, 68, 69, 70] indices\n",
      "100 target_index\n",
      "[6, 7, 8, 9, 10, 11, 12, 13, 14, 15] indices\n",
      "63 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 533 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230726161243_05572006_006_02.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 262 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230726161243_05572006_006_02.h5_gt2lgt2r is empty\n",
      "[11, 12, 13, 14, 15, 16, 76, 77, 78, 79] indices\n",
      "76 target_index\n",
      "photon less than 200!\n",
      "<class 'pandas.core.series.Series'> type mask 338 mask len\n",
      "------------------------------------\n",
      "No_28_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230726161243_05572006_006_02.h5 is done\n",
      "53.85% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "93 target_index\n",
      "[96, 97, 98, 99, 100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 435 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 425 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230828144022_10602006_006_02.h5_gt1lgt1r is empty\n",
      "[88, 89, 90, 91, 92, 93, 94, 95, 96, 97] indices\n",
      "88 target_index\n",
      "[94, 95, 96, 97, 98, 99, 100] indices\n",
      "94 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 412 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 382 mask len\n",
      "[92, 93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "92 target_index\n",
      "[94, 95, 96, 97, 98, 99, 100] indices\n",
      "94 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 364 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 353 mask len\n",
      "------------------------------------\n",
      "No_32_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230828144022_10602006_006_02.h5 is done\n",
      "61.54% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1803 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230908014207_12202002_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 1772 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230908014207_12202002_006_02.h5_gt1lgt1r is empty\n",
      "[] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 700 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230908014207_12202002_006_02.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 671 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20230908014207_12202002_006_02.h5_gt2lgt2r is empty\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[] indices\n",
      "100 target_index\n",
      "[] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 536 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231025115221_05572106_006_02.h5_gt1lgt1r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 564 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231025115221_05572106_006_02.h5_gt1lgt1r is empty\n",
      "[100] indices\n",
      "100 target_index\n",
      "[100] indices\n",
      "100 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1674 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231025115221_05572106_006_02.h5_gt2lgt2r is empty\n",
      "<class 'pandas.core.series.Series'> type mask 1642 mask len\n",
      "G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231025115221_05572106_006_02.h5_gt2lgt2r is empty\n",
      "[78, 79, 80, 81, 82, 83, 84, 85, 86, 87] indices\n",
      "78 target_index\n",
      "[76, 77, 78, 79, 80, 81, 82, 83, 84, 85] indices\n",
      "76 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1754 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1632 mask len\n",
      "------------------------------------\n",
      "No_40_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231025115221_05572106_006_02.h5 is done\n",
      "76.92% is done\n",
      "[94, 95, 96, 97, 98, 99, 100] indices\n",
      "94 target_index\n",
      "[93, 94, 95, 96, 97, 98, 99, 100] indices\n",
      "93 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 298 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 299 mask len\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "[66, 67, 68, 69, 70, 71, 72, 73, 74, 75] indices\n",
      "66 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 332 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 368 mask len\n",
      "[73, 74, 75, 76, 77, 78, 79, 80, 81, 82] indices\n",
      "73 target_index\n",
      "[71, 72, 73, 74, 75, 76, 77, 78, 79, 80] indices\n",
      "71 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 282 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 289 mask len\n",
      "------------------------------------\n",
      "No_41_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231029114405_06182106_006_01.h5 is done\n",
      "78.85% is done\n",
      "[53, 54, 55, 56, 57, 58, 59, 60, 61, 62] indices\n",
      "53 target_index\n",
      "[54, 55, 56, 57, 58, 59, 60, 61, 62, 63] indices\n",
      "54 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 885 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1389 mask len\n",
      "[72, 73, 74, 75, 76, 77, 78, 79, 80, 81] indices\n",
      "72 target_index\n",
      "[71, 72, 73, 74, 75, 76, 77, 78, 79, 80] indices\n",
      "71 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1417 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1624 mask len\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "[74, 75, 76, 77, 78, 79, 80, 81, 82, 83] indices\n",
      "74 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 1194 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 1481 mask len\n",
      "------------------------------------\n",
      "No_42_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231108224543_07782102_006_01.h5 is done\n",
      "80.77% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] indices\n",
      "44 target_index\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] indices\n",
      "44 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 690 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 764 mask len\n",
      "[62, 63, 64, 65, 66, 67, 68, 69, 70, 71] indices\n",
      "62 target_index\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69] indices\n",
      "60 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 904 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 995 mask len\n",
      "[66, 67, 68, 69, 70, 71, 72, 73, 74, 75] indices\n",
      "66 target_index\n",
      "[66, 67, 68, 69, 70, 71, 72, 73, 74, 75] indices\n",
      "66 target_index\n",
      "<class 'pandas.core.series.Series'> type mask 351 mask len\n",
      "<class 'pandas.core.series.Series'> type mask 383 mask len\n",
      "------------------------------------\n",
      "No_50_G:\\ICESat-2\\Region1\\Region1_2023\\ATL03_Region1_2023\\ATL03_20231226085557_01152206_006_02.h5 is done\n",
      "96.15% is done\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "photon less than 200!\n",
      "output_len:  12104\n",
      "     distance  mean_height  mean_lon   mean_lat       OSGM        OH Strip_No\n",
      "0  14171490.0    48.035336  0.856866  52.969387  44.833000  3.202335   0_gt1l\n",
      "1  14171550.0    49.149311  0.856782  52.968865  44.833000  4.316311   0_gt1l\n",
      "2  14171580.0    48.619995  0.856744  52.968642  44.833000  3.786995   0_gt1l\n",
      "3  14171670.0    47.696960  0.856599  52.967816  44.845001  2.851959   0_gt1l\n",
      "4  14171700.0    47.808968  0.856555  52.967558  44.845001  2.963966   0_gt1l\n",
      "5  14171730.0    48.092785  0.856509  52.967285  44.845001  3.247784   0_gt1l\n",
      "6  14171760.0    47.933376  0.856465  52.967011  44.845001  3.088375   0_gt1l\n",
      "7  14171790.0    47.540627  0.856420  52.966724  44.845001  2.695625   0_gt1l\n",
      "8  14172090.0    47.431599  0.855978  52.964047  44.845001  2.586597   0_gt1l\n",
      "9  14172120.0    47.484524  0.855939  52.963793  44.845001  2.639523   0_gt1l\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "    #----------------------------------------------------------------------------------------\n",
    "    #--------------------------------------Region 1 -----------------------------------------\n",
    "    #2019, \n",
    "    year_list = [2019, 2020, 2021, 2022, 2023]\n",
    "    # year_list = \n",
    "    Region_info = {\n",
    "            'region1': {'name':'Thames'  , 'mask':[[0.273, 1.475], [51.262, 51.863]]},\n",
    "            'region2': {'name':'Region1a', 'mask':[[0.803, 1.831], [52.479, 53.031]]},\n",
    "            'region3': {'name':'Region1b', 'mask':[[1.007, 1.842], [51.820, 52.481]]},\n",
    "            'region4': {'name':'Region1c', 'mask':[[0.518, 1.541], [50.820, 51.257]]},\n",
    "        }\n",
    "    detect_region = 'region3'\n",
    "\n",
    "    print('region:' ,Region_info[detect_region]['name'])\n",
    "    print('region_mask:', Region_info[detect_region]['mask'])\n",
    "\n",
    "    region_name = Region_info[detect_region]['name']\n",
    "    mask = Region_info[detect_region]['mask']\n",
    "    TF_height_range = [30, 70]\n",
    "    #----------------------------------------------------------------------------------------\n",
    "    for j in range(len(year_list)):\n",
    "\n",
    "        year = year_list[j]\n",
    "\n",
    "        output_root_path = f'G:\\ICESat-2\\Region1\\Region1_{region_name}'\n",
    "        if not os.path.exists(output_root_path):\n",
    "            os.makedirs(output_root_path)\n",
    "            output_path = f'G:\\ICESat-2\\Region1\\Region1_{region_name}\\A_{region_name}_30m_{year}_new10.csv'\n",
    "        else:\n",
    "            output_path = f'G:\\ICESat-2\\Region1\\Region1_{region_name}\\A_{region_name}_30m_{year}_new10.csv'\n",
    "\n",
    "        log_path =  f'G:\\ICESat-2\\Region1\\Region1_{region_name}\\A_log_{region_name}_{year}_new10.txt'\n",
    "        \n",
    "\n",
    "        folder_path_03  = f'G:\\ICESat-2\\Region1\\Region1_{year}\\ATL03_Region1_{year}'\n",
    "        folder_path_08 =  f'G:\\ICESat-2\\Region1\\Region1_{year}\\ATL08_Region1_{year}' \n",
    "        #beam = ['gt1l', 'gt2l', 'gt3l', 'gt1r', 'gt2r', 'gt3r']\n",
    "        beam = [['gt1l', 'gt1r'], ['gt2l', 'gt2r'] ,['gt3l', 'gt3r']]\n",
    "        ATL_name_group = get_atl_group(folder_path_03, folder_path_08)\n",
    "        \n",
    "        output = []\n",
    "        log_list = []\n",
    "        \n",
    "        for i in range(len(ATL_name_group)):\n",
    "        # for i in range(3):\n",
    "        # for i in range(20, 21):\n",
    "            \n",
    "            filepath_03 = ATL_name_group[i][0]\n",
    "            filepath_08 = ATL_name_group[i][1]\n",
    "            \n",
    "            merged_df, _, _, log = icesat_gt_processing3_new(i, filepath_03, filepath_08, beam, mask, TF_height_range,  30, sea_thred = 0.05, is_display = False)\n",
    "            \n",
    "            if merged_df.empty:\n",
    "                continue\n",
    "            \n",
    "            print('------------------------------------')\n",
    "            output.append(merged_df)\n",
    "            print('No_'+str(i) + '_' + str(filepath_03) + ' is done')\n",
    "            print(str(round(i*100/len(ATL_name_group), 2))+ '%' + ' is done')\n",
    "            log.append('No_'+str(i) + ': ' + str(filepath_03) + '\\n')\n",
    "            log_list.append(log)\n",
    "         #-----------------------------output log info-------------------------------------- \n",
    "        \n",
    "        with open(log_path, \"w\") as file:\n",
    "            for logs in log_list:\n",
    "                for log in logs:\n",
    "                    file.write(log)\n",
    "        #-------------------------- output result-------------------------------------------\n",
    "              \n",
    "        output = pd.concat(output, ignore_index=True) \n",
    "        print('output_len: ',len(output))\n",
    "        print(output[:10])\n",
    "        output.to_csv(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
